{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-summarization-spacy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoJBmfgfUZma",
        "outputId": "4d6e4551-34c3-43c1-bdf9-63d2bd125118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "r5V5yUDWUcCH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "oYG4GUsJUi8w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Toxic discussions on open-source GitHub projects tend to involve entitlement, subtle insults, and arrogance, according to an academic study. That contrasts with the toxic behavior – typically bad language, hate speech, and harassment – found on other corners of the web. Whether that seems obvious or not, it's an interesting point to consider because, for one thing, it means technical and non-technical methods to detect and curb toxic behavior on one part of the internet may not therefore work well on GitHub, and if you're involved in communities on the code-hosting giant, you may find this research useful in combating trolls and unacceptable conduct. It may also mean systems intended to automatically detect and report toxicity in open-source projects, or at least ones on GitHub, may need to be developed specifically for that task due to their unique nature.\""
      ],
      "metadata": {
        "id": "uHW8S2hPUnMW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "QNZoKGuzUxwd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list(doc.sents)\n",
        "print(len(sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvVb7MzFU1ed",
        "outputId": "5fdb528b-7ead-434b-b2bf-77366a1d4eb9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oydtEC0PVBpO",
        "outputId": "54100bbd-1807-4617-8684-deae2945f6ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toxic discussions on open-source GitHub projects tend to involve entitlement, subtle insults, and arrogance, according to an academic study.\n",
            "That contrasts with the toxic behavior – typically bad language, hate speech, and harassment – found on other corners of the web.\n",
            "Whether that seems obvious or not, it's an interesting point to consider because, for one thing, it means technical and non-technical methods to detect and curb toxic behavior on one part of the internet may not therefore work well on GitHub, and if you're involved in communities on the code-hosting giant, you may find this research useful in combating trolls and unacceptable conduct.\n",
            "It may also mean systems intended to automatically detect and report toxicity in open-source projects, or at least ones on GitHub, may need to be developed specifically for that task due to their unique nature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(\"Token: {}, index: {}, , lemmatized_token: {}\".format(token, token.idx, token.lemma_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdAYTNW9VDQ9",
        "outputId": "538b0d9d-178c-4a69-9acf-6a4f66704e41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Whilst, index: 0, , lemmatized_token: whilst\n",
            "Token: the, index: 7, , lemmatized_token: the\n",
            "Token: crypto, index: 11, , lemmatized_token: crypto\n",
            "Token: markets, index: 18, , lemmatized_token: market\n",
            "Token: have, index: 26, , lemmatized_token: have\n",
            "Token: taken, index: 31, , lemmatized_token: take\n",
            "Token: a, index: 37, , lemmatized_token: a\n",
            "Token: pretty, index: 39, , lemmatized_token: pretty\n",
            "Token: public, index: 46, , lemmatized_token: public\n",
            "Token: downturn, index: 53, , lemmatized_token: downturn\n",
            "Token: of, index: 62, , lemmatized_token: of\n",
            "Token: late, index: 65, , lemmatized_token: late\n",
            "Token: ,, index: 69, , lemmatized_token: ,\n",
            "Token: this, index: 71, , lemmatized_token: this\n",
            "Token: is, index: 76, , lemmatized_token: be\n",
            "Token: a, index: 79, , lemmatized_token: a\n",
            "Token: great, index: 81, , lemmatized_token: great\n",
            "Token: time, index: 87, , lemmatized_token: time\n",
            "Token: to, index: 92, , lemmatized_token: to\n",
            "Token: experiment, index: 95, , lemmatized_token: experiment\n",
            "Token: and, index: 106, , lemmatized_token: and\n",
            "Token: build, index: 110, , lemmatized_token: build\n",
            "Token: your, index: 116, , lemmatized_token: your\n",
            "Token: own, index: 121, , lemmatized_token: own\n",
            "Token: web3, index: 125, , lemmatized_token: web3\n",
            "Token: projects, index: 130, , lemmatized_token: project\n",
            "Token: ., index: 138, , lemmatized_token: .\n",
            "Token: Ether, index: 140, , lemmatized_token: Ether\n",
            "Token: ,, index: 145, , lemmatized_token: ,\n",
            "Token: and, index: 147, , lemmatized_token: and\n",
            "Token: almost, index: 151, , lemmatized_token: almost\n",
            "Token: all, index: 158, , lemmatized_token: all\n",
            "Token: other, index: 162, , lemmatized_token: other\n",
            "Token: cryptocurrencies, index: 168, , lemmatized_token: cryptocurrencie\n",
            "Token: ,, index: 184, , lemmatized_token: ,\n",
            "Token: are, index: 186, , lemmatized_token: be\n",
            "Token: cheaper, index: 190, , lemmatized_token: cheap\n",
            "Token: to, index: 198, , lemmatized_token: to\n",
            "Token: get, index: 201, , lemmatized_token: get\n",
            "Token: your, index: 205, , lemmatized_token: your\n",
            "Token: hands, index: 210, , lemmatized_token: hand\n",
            "Token: on, index: 216, , lemmatized_token: on\n",
            "Token: ,, index: 218, , lemmatized_token: ,\n",
            "Token: gas, index: 220, , lemmatized_token: gas\n",
            "Token: fees, index: 224, , lemmatized_token: fee\n",
            "Token: (, index: 229, , lemmatized_token: (\n",
            "Token: the, index: 230, , lemmatized_token: the\n",
            "Token: transaction, index: 234, , lemmatized_token: transaction\n",
            "Token: fees, index: 246, , lemmatized_token: fee\n",
            "Token: paid, index: 251, , lemmatized_token: pay\n",
            "Token: when, index: 256, , lemmatized_token: when\n",
            "Token: using, index: 261, , lemmatized_token: use\n",
            "Token: blockchain, index: 267, , lemmatized_token: blockchain\n",
            "Token: networks, index: 278, , lemmatized_token: network\n",
            "Token: ), index: 286, , lemmatized_token: )\n",
            "Token: are, index: 288, , lemmatized_token: be\n",
            "Token: much, index: 292, , lemmatized_token: much\n",
            "Token: lower, index: 297, , lemmatized_token: low\n",
            "Token: than, index: 303, , lemmatized_token: than\n",
            "Token: their, index: 308, , lemmatized_token: their\n",
            "Token: 2021, index: 314, , lemmatized_token: 2021\n",
            "Token: highs, index: 319, , lemmatized_token: high\n",
            "Token: and, index: 325, , lemmatized_token: and\n",
            "Token: now, index: 329, , lemmatized_token: now\n",
            "Token: is, index: 333, , lemmatized_token: be\n",
            "Token: your, index: 336, , lemmatized_token: your\n",
            "Token: chance, index: 341, , lemmatized_token: chance\n",
            "Token: to, index: 348, , lemmatized_token: to\n",
            "Token: learn, index: 351, , lemmatized_token: learn\n",
            "Token: a, index: 357, , lemmatized_token: a\n",
            "Token: new, index: 359, , lemmatized_token: new\n",
            "Token: skill, index: 363, , lemmatized_token: skill\n",
            "Token: that, index: 369, , lemmatized_token: that\n",
            "Token: could, index: 374, , lemmatized_token: could\n",
            "Token: be, index: 380, , lemmatized_token: be\n",
            "Token: very, index: 383, , lemmatized_token: very\n",
            "Token: valuable, index: 388, , lemmatized_token: valuable\n",
            "Token: going, index: 397, , lemmatized_token: go\n",
            "Token: forward, index: 403, , lemmatized_token: forward\n",
            "Token: ., index: 410, , lemmatized_token: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
        "word_freq = Counter(words)\n",
        "\n",
        "common_words = word_freq.most_common(5)\n",
        "\n",
        "print(common_words)\n",
        "print(\"Unique words-------------------------\")\n",
        "unique_words = [word for (word, freq) in word_freq.items() if freq ==1]\n",
        "print(unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGQhGcuNVVuP",
        "outputId": "718fef50-3180-4bc1-981d-a474c08881f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('GitHub', 3), ('open', 2), ('source', 2), ('projects', 2), ('toxic', 2)]\n",
            "Unique words-------------------------\n",
            "['Toxic', 'discussions', 'tend', 'involve', 'entitlement', 'subtle', 'insults', 'arrogance', 'according', 'academic', 'study', 'contrasts', 'typically', 'bad', 'language', 'hate', 'speech', 'harassment', 'found', 'corners', 'web', 'obvious', 'interesting', 'point', 'consider', 'thing', 'means', 'non', 'methods', 'curb', 'internet', 'work', 'involved', 'communities', 'code', 'hosting', 'giant', 'find', 'research', 'useful', 'combating', 'trolls', 'unacceptable', 'conduct', 'mean', 'systems', 'intended', 'automatically', 'report', 'toxicity', 'ones', 'need', 'developed', 'specifically', 'task', 'unique', 'nature']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "Zfg9J0ZaWjzB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = []\n",
        "stopwords = list(STOP_WORDS)\n",
        "pos_tag = ['PROPN','ADJ','NOUN','VERB']\n",
        "for token in doc:\n",
        "     if(token.text in stopwords or token.text in punctuation):\n",
        "          continue\n",
        "     if(token.pos_ in pos_tag): \n",
        "          keyword.append(token.text) \n",
        "print(keyword)\n",
        "freq_word = Counter(keyword) \n",
        "print(freq_word.most_common(5))\n",
        "print(\"2. Sentence Strength =====================================\") \n",
        "sent_strength = {}\n",
        "for sent in doc.sents:\n",
        "     for word in sent:\n",
        "          if word.text in freq_word.keys():\n",
        "               if sent in sent_strength.keys():\n",
        "                    sent_strength[sent]+=freq_word[word.text] \n",
        "               else:\n",
        "                    sent_strength[sent]=freq_word[word.text] \n",
        "print(sent_strength)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ITE4BGWWRDe",
        "outputId": "64138ea6-b57e-4ecf-b9b4-8e9e6af63a11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Toxic', 'discussions', 'open', 'source', 'GitHub', 'projects', 'tend', 'involve', 'entitlement', 'subtle', 'insults', 'arrogance', 'according', 'academic', 'study', 'contrasts', 'toxic', 'behavior', 'bad', 'language', 'hate', 'speech', 'harassment', 'found', 'corners', 'web', 'obvious', 'interesting', 'point', 'consider', 'thing', 'means', 'technical', 'non', 'technical', 'methods', 'detect', 'curb', 'toxic', 'behavior', 'internet', 'work', 'GitHub', 'involved', 'communities', 'code', 'hosting', 'giant', 'find', 'research', 'useful', 'combating', 'trolls', 'unacceptable', 'conduct', 'mean', 'systems', 'intended', 'detect', 'report', 'toxicity', 'open', 'source', 'projects', 'ones', 'GitHub', 'need', 'developed', 'task', 'unique', 'nature']\n",
            "[('GitHub', 3), ('open', 2), ('source', 2), ('projects', 2), ('toxic', 2)]\n",
            "2. Sentence Strength =====================================\n",
            "{Toxic discussions on open-source GitHub projects tend to involve entitlement, subtle insults, and arrogance, according to an academic study.: 20, That contrasts with the toxic behavior – typically bad language, hate speech, and harassment – found on other corners of the web.: 13, Whether that seems obvious or not, it's an interesting point to consider because, for one thing, it means technical and non-technical methods to detect and curb toxic behavior on one part of the internet may not therefore work well on GitHub, and if you're involved in communities on the code-hosting giant, you may find this research useful in combating trolls and unacceptable conduct.: 36, It may also mean systems intended to automatically detect and report toxicity in open-source projects, or at least ones on GitHub, may need to be developed specifically for that task due to their unique nature.: 22}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summerized_sentences = nlargest(3,sent_strength,key=sent_strength. \n",
        "get)\n",
        "print(summerized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG0CYpy7Wq2n",
        "outputId": "785c430d-b333-4e8e-9fea-753b5e1efa53"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Whether that seems obvious or not, it's an interesting point to consider because, for one thing, it means technical and non-technical methods to detect and curb toxic behavior on one part of the internet may not therefore work well on GitHub, and if you're involved in communities on the code-hosting giant, you may find this research useful in combating trolls and unacceptable conduct., It may also mean systems intended to automatically detect and report toxicity in open-source projects, or at least ones on GitHub, may need to be developed specifically for that task due to their unique nature., Toxic discussions on open-source GitHub projects tend to involve entitlement, subtle insults, and arrogance, according to an academic study.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input sentence:**\n",
        "Whilst the crypto markets have taken a pretty public downturn of late, this is a great time to experiment and build your own web3 projects. Ether, and almost all other cryptocurrencies, are cheaper to get your hands on, gas fees (the transaction fees paid when using blockchain networks) are much lower than their 2021 highs and now is your chance to learn a new skill that could be very valuable going forward.\n",
        "\n",
        "**Output summary:**\n",
        "Ether, and almost all other cryptocurrencies, are cheaper to get your hands on, gas fees (the transaction fees paid when using blockchain networks) are much lower than their 2021 highs and now is your chance to learn a new skill that could be very valuable going forward., Whilst the crypto markets have taken a pretty public downturn of late, this is a great time to experiment and build your own web3 projects."
      ],
      "metadata": {
        "id": "q9q2u9jcWvJ5"
      }
    }
  ]
}